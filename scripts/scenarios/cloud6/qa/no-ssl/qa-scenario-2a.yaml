---
# 2a - 8 nodes, HA (SBD 3x2), KVM x 1
proposals:
- barclamp: pacemaker
  name: services
  attributes:
    stonith:
      mode: sbd
      sbd:
        nodes:
          "@@controller1@@":
            devices:
            - "@@sbd_device_services@@"
          "@@controller2@@":
            devices:
            - "@@sbd_device_services@@"
      per_node:
        nodes:
          "@@controller1@@":
            params: ''
          "@@controller2@@":
            params: ''
  deployment:
    elements:
      pacemaker-cluster-member:
      - "@@controller1@@"
      - "@@controller2@@"
      hawk-server:
      - "@@controller1@@"
      - "@@controller2@@"

- barclamp: pacemaker
  name: data
  attributes:
    stonith:
      mode: sbd
      sbd:
        nodes:
          "@@data1@@":
            devices:
            - "@@sbd_device_data@@"
          "@@data2@@":
            devices:
            - "@@sbd_device_data@@"
      per_node:
        nodes:
          "@@data1@@":
            params: ''
          "@@data2@@":
            params: ''
  deployment:
    elements:
      pacemaker-cluster-member:
      - "@@data1@@"
      - "@@data2@@"
      hawk-server:
      - "@@data1@@"
      - "@@data2@@"

- barclamp: pacemaker
  name: network
  attributes:
    stonith:
      mode: sbd
      sbd:
        nodes:
          "@@network1@@":
            devices:
            - "@@sbd_device_network@@"
          "@@network2@@":
            devices:
            - "@@sbd_device_network@@"
      per_node:
        nodes:
          "@@network1@@":
            params: ''
          "@@network2@@":
            params: ''
  deployment:
    elements:
      pacemaker-cluster-member:
      - "@@network1@@"
      - "@@network2@@"
      hawk-server:
      - "@@network1@@"
      - "@@network2@@"

- barclamp: database
  attributes:
    ha:
      storage:
        shared:
          device: ##shared_nfs_for_database##
          fstype: nfs
          options: nfsvers=3
  deployment:
    elements:
      database-server:
      - cluster:data

- barclamp: rabbitmq
  attributes:
    trove:
      enabled: true
    ha:
      storage:
        shared:
          device: ##shared_nfs_for_rabbitmq##
          fstype: nfs
          options: nfsvers=3
  deployment:
    elements:
      rabbitmq-server:
      - cluster:data

- barclamp: keystone
  attributes:
    signing:
      token_format: UUID
  deployment:
    elements:
      keystone-server:
      - cluster:services

- barclamp: swift
  attributes:
    replicas: 2
    keystone_delay_auth_decision: true
    allow_versions: true
  deployment:
    elements:
      swift-dispersion:
      - "@@controller1@@"
      swift-proxy:
      - cluster:services
      swift-ring-compute:
      - "@@controller1@@"
      swift-storage:
      - "@@computekvm1@@"
      - "@@computekvm2@@"

- barclamp: glance
  attributes:
    default_store: swift
  deployment:
    elements:
      glance-server:
      - cluster:services

- barclamp: cinder
  attributes:
    volumes:
    - backend_driver: nfs
      backend_name: nfs
      nfs:
        nfs_shares: ##cinder-storage-shares##
        nfs_mount_options: nfsvers=3,rw,sync,nofail
  deployment:
    elements:
      cinder-controller:
      - cluster:services
      cinder-volume:
      - "@@data1@@"
      - "@@data2@@"

- barclamp: neutron
  attributes:
    ml2_mechanism_drivers:
    - linuxbridge
    ml2_type_drivers:
    - vlan
    ml2_type_drivers_default_provider_network: vlan
    ml2_type_drivers_default_tenant_network: vlan
    use_lbaas: false
  deployment:
    elements:
      neutron-server:
      - cluster:network
      neutron-network:
      - cluster:network

- barclamp: nova
  attributes:
    itxt_instance: ''
    use_migration: true
    vnc_keymap: de
    kvm:
      ksm_enabled: true
  deployment:
    elements:
      nova-controller:
      - cluster:services
      nova-compute-hyperv: []
      nova-compute-kvm:
      - "@@computekvm1@@"
      - "@@computekvm2@@"
      nova-compute-qemu: []
      nova-compute-xen: []

# Because neutron and nova are deployed on different clusters, we need
# to commit neutron proposal again after nova to pick up the nova authentication
- barclamp: neutron
  attributes:
    use_lbaas: true

- barclamp: horizon
  attributes:
  deployment:
    elements:
      horizon-server:
      - cluster:services

- barclamp: heat
  attributes:
  deployment:
    elements:
      heat-server:
      - cluster:services

- barclamp: ceilometer
  attributes:
  deployment:
    elements:
      ceilometer-agent:
      - "@@computekvm1@@"
      - "@@computekvm2@@"
      ceilometer-agent-hyperv: []
      ceilometer-central:
      - cluster:services
      ceilometer-server:
      - cluster:services
      ceilometer-swift-proxy-middleware: []

- barclamp: manila
  attributes:
    default_share_type: default
    shares:
    - backend_driver: netapp
      backend_name: netapp1
      netapp:
        netapp_storage_family: ontap_cluster
        netapp_server_hostname: ##netapp_server##
        netapp_server_port: 80
        netapp_login: admin
        netapp_password: ##netapp_password##
        netapp_vserver: ##netapp_vserver##
        netapp_transport_type: http
  deployment:
    elements:
      manila-server:
      - cluster:services
      manila-share:
      - "@@data1@@"
      - "@@data2@@"

- barclamp: trove
  attributes:
    volume_support: true
  deployment:
    elements:
      trove-server:
        - cluster:services

- barclamp: tempest
  attributes:
  deployment:
    elements:
      tempest:
      - "@@controller1@@"
